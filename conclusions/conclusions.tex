\chapter{Conclusions and Future Work}
\label{chap:conclusions}

\section{General Conclusions}
This thesis presents three years' work on understanding and improving the analysis tools used in confocal sFRET experiments. This work has involved boh implementing and benchmarking existing techniques, as well as implementing and thoroughly evaluating novel methodologies. We hope that this work provides a strong foundation for rigorous work by other researchers in this field.

\subsection{pyFRET}
Chapter~\ref{chap:pyfret} described the development and release of an open source software library for the analysis of confocal smFRET data. For researchers working in different research environments to be able to cross-compare their results effectively, it is necessary that they have an effective method to describe and share their analysis tools and to select the best analysis tools for their specific research problem. Furthermore, smFRET data is quite sensitive to the analysis methods used and, as we have shown, both the specific analysis tools used and the method of their usage can quite significantly influence the appearance of the processed data and hence the outcome of donwstream analyses. Unfortunately, to date there has been no culture of publishing the code or smFRET data analysis tools, which has made it difficult for researchers to compare the effectiveness and efficiency of different analysis methods.

To overcome these challenges, we have developed and released pyFRET, a software library that implements many of the main methodologies for analysis of smFRET data. pyFRET is open source and fully documented. This provides both a toolkit of analysis methods that can be freely accessed by other researchers and a platform for researchers to contribute and benchmark novel analysis methods. We also describe a rigorous comparison of different data collection and analysis methods for confocal smFRET data. The evaluation presented here identifies the clear superiority of alternating excitation schemes that provide direct access to acceptor excitation information, enabling thresholding-based event selection to be carried out without bias. We show that without direct access to information about acceptor emission, the more complex APBS and DCBS burst search algorithms display biases comparable to those seen from the simple AND and SUM thresholding algorithms, despite significantly increased space requirements and computational complexity. We hope that this work will facilitate research by other scientists, who can now quickly and effectively select the correct analysis tool for their data, as well as providing a platform for the publication and benchmarking of novel analysis methods.

\subsection{Inference Analysis of smFRET Data}
Thresholding-based event selection for confocal smFRET data necessarily discards a significant of the smFRET dataset, including not only noise but also a large fraction of fluorescence emission events. Furthermore, as we show in Chapter~\ref{chap:pyfret}, in the absence of direct information about acceptor emisson behaviour, thresholding criteria are biased and do not select a random subset of fluorescent events, resulting in distortion of downstream analyses. To overcome these challenges we developed a novel analysis method, based on model-based Bayesian inference, that can simultaneously co-infer the values of all parameters of interest in a confocal smFRET dataset.

Chapter~\ref{chap:inference} presents the development and evaluation of this novel tool. Our evaluation shows that model-based inference is an effective tool for analysis of smFRET data and that we can accurately infer the concentrations and intramolecular distances of single fluorescent populations or of a mixture of two fluorescent populations. The full source code for our inference analysis is freely available online. This work provides a strong foundation for the application of model-based inference to a wider range of smFRET datasets and demonstrates the proof of concept that model-based inference is both feasible and fruitful as a method of data analysis for this research field.  

\subsection{Inference Analysis of Oligomer Sizing}
Chapter~\ref{chap:sizing} extends the concept of model-based inference and applies this form of analysis to the problem of accurately sizing heterogeneous mixtures of fluorescently labelled oligomers. A significant research effort has been made in the Klenerman group to develop experimental methodologies to allow accurate characterisation of the oligomerisation reactions observed in amyloidosis. The data analysis side of this effort has to date been somewhat neglected, allowing unfounded assumptions about the data collected to significantly reduce the accuracy of calculated oligomer size distributions.

The work presented in this chapter demonstrates, through a comparison of simulated datasets and data from simple, well-controlled experiments, that the heterogeneity observed in photon emission is not dominated, as would be hoped, by the number of fluorophores attached to a molecule. Instead, underlying photophysical processes, including, but not limited to, photobleaching, photoblinking, and the diffusion pathway of molecules through the confocal volume, have a more significant effect on the number of photons observed. Although this research was not able to provide a greatly improved analysis technique, we hope that our thorough evaluation of the challenges encountered in attempting to accuarately determine oligomer sizes, even in well-characterised, homogeneous samples, demonstrates the importance of thoroughly examining all assumptions implicit in any method of data analysis.   

\subsection{NxRepair}
The final results chapter, Chapter~\ref{chap:illumina}, presented work performed in a different research field; namely the development of NxRepair, an error correction tool for \emph{de novo} assemblies of bacterial genomes assembled from Illumina's Nextera nate pair reads. Although long-read technologies are being developed, these are either still experimental or prohibitively expensive for normal use. Consequently, the challenge of accurately reconstructing the sequence of an entire genome from short read sequences remains current. 

The work presented in this chapter demonstrates a novel method for error identification and error correction based on probabilistic analysis of the insert size distribution when mate pair reads are aligned back to the \emph{de novo} assembly. NxRepair is available online for free download and the source code is hosted on the popular code repository GitHub.  This chapter presents a comprehensive evaluation of the performcance of NxRepair using multiple bacterial genomes, demonstrating its superior performance when compared to the most popular existing error correction tool.

\section{Applications and Future Work}
The work presented in this thesis, and summarized above, provides a stable foundation for further work to consolidate and improve the analysis of smFRET data. Some of the results presented have encouraged experimental method development to allow more rigorous analysis of smFRET data. To conclude this thesis, we now summarize some of the applications and extensions that are being considered as a result of the work described here. 

\subsection{Open Source Software for smFRET}
pyFRET, our open source library of data analysis tools for smFRET currently provides sufficient functionality for a researcher to perform a full analysis of smFRET data collected from a range of different experiment types using a number of different methods. As the source code that implements the analysis tools, as well as the tools themselves, is freely available online it is straightforward fro researchers to understand how the analysis works and to modify the tools as they require. This prevents new users of smFRET technology from needing to develop their analysis tools from scratch in order to be able to analsye their data. 

Furthermore, as experimental technologies develop and improve, it is to be expected that new analysis tools will also be required. pyFRET provides a central repository to the community to which new techniques can be added, to allow easy access and evaluations; and against which new techniques can be benchmarked; enabling researchers to make fully informed descisions about which analysis tools and experiemental methodologies to use in their research.

pyFRET already has users outside of the Klenerman research group and we have responded to requests for additional features. There is clearly considerable work to do to allow pyFRET to become useful to a wider swathe of the smFRET research community. Howerver, we hope that its existence encourages a more open, collaborative approach to smFRET data analysis and method development. 

\subsection{Inference Analysis of smFRET Data}
The work on inference analysis on smFRET data that we have presented here clearly shows the feasibility of inference analysis as a method of analysing smFRET data. It also highlights considerable extensions and improvements to the inference method as presented here, the implementation of which would considerably increase the utility of inference as an analysis tool. The two most important of these are:

\begin{enumerate}
\item The implementation of revesible jump Monte Carlo inference~\cite{green1995}.
\item The release of the inference analysis as a software package.
\end{enumerate}

In its current implementation, the inference analysis cannot infer the number of fluorescent populations in a mixture; the number of populations must be given. This is a considerable limitation, as the number of fluorescent populations is frequently unknown. At present, determining the number of fluorescent populations can only be carried out by performing infernce multiple times, modifying the number of expected fluorescent populations, and then manually inspecting the results obtained. Implementation of reversible jump Monte Carlo sampling would make this model selection step part of the inference analysis and would greatly increase the attraction of inference as a method of smFRET data analysis. 

Similarly, although the source code for the inference analysis can be viewed and downloaded from an open source code repository (\url{https://bitbucket.org/rebecca_roisin/fret-inference}), the code is not packaged or documented in a manner that makes it easy to use. Packaging the analysis code as a software package, for example by incorporating it into the pyFRET framework, would make this analysis tool more accessible to other researchers. Making both of these improvements is likely to significantly improve the reception of inference analysis by smFRET researchers.

\subsection{Accurate Sizing of Fluorescent Oligomers}
Although the work on accurate oligomer sizing using inference methods was the least successful piece of research presented in this thesis in terms of successful method development, it is the work that has presented the greatest number of opportunities for further work. The results that we present here conclusively demonstrate the role of both photophysics and the underlying experimental methodology in preventing accurate assessment of oligomer size distributions based on fluorescence data. These conclusions have led to significant re-evaluation of the experimental methods used and to the proposal of several modifications to the research methodology that may enable a more quantitative evaluation of oligomer sizes.

Specifically, the Klenerman group is currently constructing a novel confocal microscope that uses acouso-optic modulation to allow uniform excitation of the confocal volume in the $x$-dimension. By flowing labelled molecules rapidly across this region of uniform excitation using nano-fluidic channels that confine the molecules to a narrow region in the $y$-dimension, we hope to be able to reduce the experimental sources of emission heterogeneity. Similarly, we are currently evaluating fluorophore performance, to find commercially available structures that are more robust to photobleaching and photoblinking behaviour. A thorough evaluation of the new experimental set-up is currently in progress and we are hopeful that it may lead to a more quantitative experimental methodology for determining sizes and size distributions.

\subsection{Error Detection in \emph{de novo} Assemblies}
The work presented on error correction in \emph{de novo} assemblies is predominantly self contained. We developed and released an open-source error correction tool, which is currently used by bioinformaticians at Illumina; an evaluation of the tool's performance has been submitted for peer reviewed publication. Extensions of this tool include modifications to enable larger genome assemblies to be evaluated and to allow evaluation of \emph{de novo} assemblies prepared using alternative sequencing methodologies, such as the long-reads from Nanopore sequencing that can be ``threaded'' through a de Bruijn graph to resolve ambiguities~\cite{Koren2015}. Modification of the tool to enable chaining with other assembly and quality control tools is also possibile. Implementation of these additions depends on demand and uptake from other bioinformaticians. We hope that NxRepair finds an interested user-base within the bioinformatics research community.
