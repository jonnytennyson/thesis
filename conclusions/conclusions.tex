\chapter{Conclusions and Future Work}
\label{chap:conclusions}

\section{General Conclusions}
This thesis presents three years' work on understanding and improving the analysis tools used in confocal smFRET experiments. This work has involved both implementing and benchmarking existing techniques, as well as implementing and thoroughly evaluating novel methodologies. It is hoped that this work provides a strong foundation for rigorous work by other researchers in this field.

\subsection{pyFRET}
Chapter~\ref{chap:pyfret} described the development and release of an open source software library for the analysis of confocal smFRET data. For researchers working in different research environments to be able to cross-compare their results effectively, it is necessary that they have an effective method to describe and share their analysis tools and to select the best analysis tools for their specific research problem. Furthermore, smFRET data is quite sensitive to the analysis methods used.  As shown, both the specific analysis tools used and the method of their usage can quite significantly influence the appearance of the processed data and hence the outcome of downstream analyses. Unfortunately, to date there has been no culture of publishing the code or smFRET data analysis tools, which has made it difficult for researchers to compare the effectiveness and efficiency of different analysis methods.

To overcome these challenges, pyFRET, a software library that implements many of the main methodologies for analysis of smFRET data, was developed and released. pyFRET is open source and fully documented. This provides both a toolkit of analysis methods that can be freely accessed by other researchers and a platform for researchers to contribute and benchmark novel analysis methods. A rigorous comparison of different data collection and analysis methods for confocal smFRET data was also described. The evaluation presented here identifies the clear superiority of alternating excitation schemes that provide direct access to acceptor excitation information, enabling thresholding-based event selection to be carried out without bias. It is show that without direct access to information about acceptor emission, the more complex APBS and DCBS burst search algorithms display biases comparable to those seen from the simple AND and SUM thresholding algorithms, despite significantly increased space requirements and computational complexity. It is hoped that this work will facilitate research by other scientists, who can now quickly and effectively select the correct analysis tool for their data, as well as providing a platform for the publication and benchmarking of novel analysis methods.

\subsection{Inference Analysis of smFRET Data}
Thresholding-based event selection for confocal smFRET data necessarily discards a significant fraction of the smFRET dataset, including not only noise but also a large fraction of fluorescence emission events. Furthermore, as shown in Chapter~\ref{chap:pyfret}, in the absence of direct information about acceptor emission behaviour, thresholding criteria are biased and do not select a random subset of fluorescent events, resulting in distortion of downstream analyses. To overcome these challenges, a novel analysis method was developed, based on model-based Bayesian inference, that can simultaneously co-infer the values of all parameters of interest in a confocal smFRET dataset.

Chapter~\ref{chap:inference} presents the development and evaluation of this novel tool. This evaluation shows that model-based inference is an effective tool for analysis of smFRET data and that the concentrations and intramolecular distances of single fluorescent populations or of a mixture of two fluorescent populations can be accurately inferred. The full source code for our inference analysis is freely available online. This work provides a strong foundation for the application of model-based inference to a wider range of smFRET datasets and demonstrates the proof of concept that model-based inference is both feasible and fruitful as a method of data analysis for this research field.  

\subsection{Inference Analysis of Oligomer Sizing}
Chapter~\ref{chap:sizing} extends the concept of model-based inference and applies this form of analysis to the problem of accurately sizing heterogeneous mixtures of fluorescently labelled oligomers. A significant research effort has been made in the Klenerman group to develop experimental methodologies to allow accurate characterisation of the oligomerization reactions observed in amyloidosis. The data analysis side of this effort has been somewhat neglected, allowing unfounded assumptions about the data collected to significantly reduce the accuracy of calculated oligomer size distributions.

The work presented in this chapter demonstrates, through a comparison of simulated datasets and data from simple, well-controlled experiments, that the heterogeneity observed in photon emission is not dominated, as would be hoped, by the number of fluorophores attached to a molecule. Instead, underlying photophysical processes, including, but not limited to, photobleaching, photoblinking, and the diffusion pathway of molecules through the confocal volume, have a more significant effect on the number of photons observed. Although this research was not able to provide a greatly improved analysis technique, it is hoped that the thorough evaluation presented here of the challenges encountered in attempting to accurately determine oligomer sizes, even in well-characterised, homogeneous samples, demonstrates the importance of thoroughly examining all assumptions implicit in any method of data analysis.   

\subsection{NxRepair}
The final results chapter, Chapter~\ref{chap:illumina}, presented work performed in a different research field; namely the development of NxRepair, an error correction tool for \emph{de novo} assemblies of bacterial genomes assembled from Illumina's Nextera mate pair reads. Although long-read technologies are being developed, these are either still experimental or prohibitively expensive for normal use. Consequently, the challenge of accurately reconstructing the sequence of an entire genome from short read sequences remains current. 

The work presented in this chapter demonstrates a novel method for error identification and error correction based on probabilistic analysis of the insert size distribution when mate pair reads are aligned back to the \emph{de novo} assembly. NxRepair is available online for free download and the source code is hosted on the popular code repository GitHub.  This chapter presents a comprehensive evaluation of the performance of NxRepair using multiple bacterial genomes, demonstrating its superior performance when compared to the most popular existing error correction tool.

\section{Applications and Future Work}
The work presented in this thesis, and summarized above, provides a stable foundation for further work to consolidate and improve the analysis of smFRET data. Some of the results presented have encouraged experimental method development to allow more rigorous analysis of smFRET data. To conclude this thesis, some of the applications and extensions that are being considered as a result of the work described here are now summarized. 

\subsection{Open Source Software for smFRET}
pyFRET, the open source library of data analysis tools for smFRET currently provides sufficient functionality for a researcher to perform a full analysis of smFRET data collected from a range of different experiment types using a number of different methods. As the source code that implements the analysis tools, as well as the tools themselves, is freely available online it is straightforward for researchers to understand how the analysis works and to modify the tools as they require. This prevents new users of smFRET technology from needing to develop their analysis tools from scratch in order to be able to analyse their data. 

Furthermore, as experimental technologies develop and improve, it is to be expected that new analysis tools will also be required. pyFRET provides a central repository to the community to which new techniques can be added, to allow easy access and evaluations; and against which new techniques can be benchmarked; enabling researchers to make fully informed descisions about which analysis tools and experiemental methodologies to use in their research.

It is expected that the release of this software will significantly facilitate collaboration and systematic evaluation of the analysis methods used by smFRET researchers. Recent applications of confocal smFRET analysis include real-time analysis of DNA recombination~\cite{May2015} and following protein folding inside living cells~\cite{Sustarsic2015}. Theser are applications that require accurate and detailed reporting of of small changes in intramoleclar distances against a noisy background, particularly when experiments are performed in cytoplasmic solutions. Hence, it is important that researchers are confident both that they are using the most sensitive and accurate analysis available, but also that they are not using a method that significantly increases the duration, storage requirements and complexity of their data collection methods for no additional gain in analytical performance. The benchmarking of smFRET analysis methods described here should considerably facilitate the correct selection of appropriate data collection and analysis methods.

Furthermore, as smFRET moves beyond proof-of-concept experiments to become a more mainstream experimental technology, the techniques are being adopted by more diverse research groups with less experience in single-molecule biophysics and data analysis. Currently, there is little sharing of expertise between research groups, meaning that new entrants to the field must use software developed in-house and hence must currently implement the large part of their work from scratch as neither free nor commercial software is available for many analysis applications. As an example, researchers at the University of Wollongong are using smFRET techniques to extend their recent studies into neurodegenerative disease~\cite{Hochberg2013}. By collaborating with the Klenerman group, they were able to implement smFRET analyses over a much shorter timescale than would have been possible without such sharing of expertise. The release of the pyFRET library should help other such groups implement their own smFRET analyses with the minimum of difficulty, as it provides ready-made scripts, removing the need for re-implementation of existing software tools. pyFRET already has users outside of the Klenerman research group and requests for additional features have been satisfied. There is clearly considerable work to do to allow pyFRET to become useful to a wider swathe of the smFRET research community. However, it is hoped that its existence encourages a more open, collaborative approach to smFRET data analysis and method development. 

\subsection{Inference Analysis of smFRET Data}
The work on inference analysis on smFRET data presented here clearly shows the feasibility of inference analysis as a method of analysing smFRET data. This work is complementary to research performed in TIRF microscopy, which has used inference-based analysis to identify changes in FRET signal with time from tethered molecules undergoing confomational change~\cite{mckinney06} and to estimate the barrier-crossing time for the folding of individual proteins~\cite{chung2013}. These sophisticated analysis methods facilitate insight into the mechanisms and energy barriers for individual molecules. We hope that the precision offered by the inference analysis enables such detail to be obtained from confocal smFRET experiments.

A second advantage of the inference analysis presented here is that it enables accurate analysis of fluorescent events against a much noiser background and using considerably less data than traditional thresholding analyses. As confocal smFRET is deployed more frequently to study conformational changes~\cite{Sustarsic2015} and molecular translocations~\cite{Kusumi2013} inside living cells, the availablility of analysis techniques that can perform well when the SNR is low, or when only small volumes of data are available, is only going to become more important. The inference analysis methods that are described here are an attractive option for research that requires high sensitivity under challenging experimental conditions.

Finally, as the understanding of the physical process of fluorescence emission is elucidated, for example through the excellent theoretical work of Gopich and Szabo~\cite{gopich07, gopich09, gopich12}, it is clear that, at the single molecle level, fluorescence emission is an inherently stochastic phenomenon, which can be approximated well by a probabilistic model. Hence, the work described here, which takes a model-based approach to the analysis of smFRET data, is grounded in our understanding of the physical processes. The fact that such a simplified model can be used to fully analyse real experimental data helps to bridge the gap between theoretical studies of fluorescence phenomena and the applied research that makes use of them.


However, the work as presented here also highlights considerable extensions and improvements to the inference method as presented here, the implementation of which would considerably increase the utility of inference as an analysis tool. The two most important of these are:

\begin{enumerate}
\item The implementation of reversible jump Monte Carlo inference~\cite{green1995}.
\item The release of the inference analysis as a software package.
\end{enumerate}

In its current implementation, the inference analysis cannot infer the number of fluorescent populations in a mixture; the number of populations must be given. This is a considerable limitation, as the number of fluorescent populations is frequently unknown. At present, determining the number of fluorescent populations can only be carried out by performing inference multiple times, modifying the number of expected fluorescent populations, and then manually inspecting the results obtained. Implementation of reversible jump Monte Carlo sampling would make this model selection step part of the inference analysis and would greatly increase the attraction of inference as a method of smFRET data analysis. 

Similarly, although the source code for the inference analysis can be viewed and downloaded from an open source code repository, the code is not packaged or documented in a manner that makes it easy to use. Packaging the analysis code as a software package, for example by incorporating it into the pyFRET framework, would make this analysis tool more accessible to other researchers. Making both of these improvements is likely to significantly improve the reception of inference analysis by smFRET researchers.

\subsection{Accurate Sizing of Fluorescent Oligomers}
Although the work on accurate oligomer sizing using inference methods was the least successful piece of research presented in this thesis in terms of successful method development, it is the work that has presented the greatest number of opportunities for further work and which has the widest implications for other research using confocal smFRET. The results that are presented here conclusively demonstrate the role of both photophysics and the underlying experimental methodology in preventing accurate assessment of oligomer size distributions based on fluorescence data.

Neurodegenerative disease is an area of extremely active research and also one that presents many challenges. The population of amyloid oligomers is highly heterogeneous, which presents many analysis complexities. Hence, smFRET analysis has been a very attractive method to enable the detailed study of these heterogeneus mixtures~\cite{cremades2012}. It is important that the limitations of this technique, described in detail in this thesis, are widely disseminated, to prevent further waste of scarce funding resources on a field of study that is unlikely to lead to high-quality, informative results.

Furthermore, the conclusions drawn here about the accuracy of molecular sizing methodologies that are based on the total number of photons emitted are not limited to confocal smFRET, nor to its application to the study of amyloid oligomers. As the data from photobleaching step analysis on synthetic oligomers shows, the effects of photoblinking and photobleaching also broaden the distribution of observed photons emitted during a TIRF excitation experiment. This phenomenon would be observed in any experiment, on any labelled molecule, for example multimeric membrane proteins~\cite{Fricke2015} or complexes of intriniscally diordered proteins~\cite{Lee2015}, meaning that any attempts at oligomer or protein complex sizing that make use of the number of emitted photons are likely to encounter the same difficulties.

These conclusions have led to significant re-evaluation of the experimental methods used and to the proposal of several modifications to the research methodology that may enable a more quantitative evaluation of oligomer sizes.Specifically, the Klenerman group is currently constructing a novel confocal microscope that uses acousto-optic modulation to allow uniform excitation of the confocal volume in the $x$-dimension. By flowing labelled molecules rapidly across this region of uniform excitation using nanofluidic channels that confine the molecules to a narrow region in the $y$-dimension, it may be possible to reduce the experimental sources of emission heterogeneity. Similarly, fluorophore performance is currently being evaluated, to find commercially available structures that are more robust to photobleaching and photoblinking behaviour. A thorough evaluation of the new experimental set-up is currently in progress and it is hoped that this may lead to a more quantitative experimental methodology for determining sizes and size distributions.

\subsection{Error Detection in \emph{de novo} Assemblies}
The work presented on error correction in \emph{de novo} assemblies is predominantly self contained. An open-source error correction tool was developed and released. This tool is currently used by bioinformaticians at Illumina; an evaluation of the tool's performance forms the basis for a peer reviewed publication~\cite{murphy2015}. 

\emph{De novo} assemblies of genomes are frequently released, as the price of sequencing continues to fall, complete sequence assemblies become financiallt feasible in many areas of research. In the last year, \emph{de novo} assemblies have been published on a diverse range of species, including a haplotype-resolution human genome~\cite{Cao2015} and multiple plant species~\cite{Xie2015, Fukushima2015}. As sequencing technology enters the mainstream and is used more frequently to inform downstream research, it is important that methods exist to evaluate the quality of \emph{de novo} genome assemblies and to identify or remove errors that may lead to incorrect conclusions being drawn from the genomic data. NxRepair is a tool that can be used for such a purpose and can be used in conjunction with existing tools to enhance the quality of \emph{de novo} assemblies.

Extensions of this tool include modifications to enable larger genome assemblies to be evaluated and to allow evaluation of \emph{de novo} assemblies prepared using alternative sequencing methodologies, such as the long-reads from Nanopore sequencing that can be ``threaded'' through a de Bruijn graph to resolve ambiguities~\cite{Koren2015}. Modification of the tool to enable chaining with other assembly and quality control tools is also possible. Implementation of these additions depends on demand and uptake from other bioinformaticians. It is hoped that NxRepair finds an interested user-base within the bioinformatics research community.
