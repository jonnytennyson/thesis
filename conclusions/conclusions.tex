\chapter{Conclusions and Future Work}
\label{chap:conclusions}

\section{General Conclusions}
This thesis presents three years' work on understanding and improving the analysis tools used in confocal sFRET experiments. This work has involved boh implementing and benchmarking existing techniques, as well as implementing and thoroughly evaluating novel methodologies. We hope that this work provides a strong foundation for rigorous work by other researchers in this field.

\subsection{pyFRET}
Chapter~\ref{chap:pyfret} described the development and release of an open source software library for the analysis of confocal smFRET data. For researchers working in different research environments to be able to cross-compare their results effectively, it is necessary that they have an effective method to describe and share their analysis tools and to select the best analysis tools for their specific research problem. Furthermore, smFRET data is quite sensitive to the analysis methods used and, as we have shown, both the specific analysis tools used and the method of their usage can quite significantly influence the appearance of the processed data and hence the outcome of donwstream analyses. Unfortunately, to date there has been no culture of publishing the code or smFRET data analysis tools, which has made it difficult for researchers to compare the effectiveness and efficiency of different analysis methods.

To overcome these challenges, we have developed and released pyFRET, a software library that implements many of the main methodologies for analysis of smFRET data. pyFRET is open source and fully documented. This provides both a toolkit of analysis methods that can be freely accessed by other researchers and a platform for researchers to contribute and benchmark novel analysis methods. We also describe a rigorous comparison of different data collection and analysis methods for confocal smFRET data. The evaluation presented here identifies the clear superiority of alternating excitation schemes that provide direct access to acceptor excitation information, enabling thresholding-based event selection to be carried out without bias. We show that without direct access to information about acceptor emission, the more complex APBS and DCBS burst search algorithms display biases comparable to those seen from the simple AND and SUM thresholding algorithms, despite significantly increased space requirements and computational complexity. We hope that this work will facilitate research by other scientists, who can now quickly and effectively select the correct analysis tool for their data, as well as providing a platform for the publication and benchmarking of novel analysis methods.

\subsection{Inference Analysis of smFRET Data}
Thresholding-based event selection for confocal smFRET data necessarily discards a significant of the smFRET dataset, including not only noise but also a large fraction of fluorescence emission events. Furthermore, as we show in Chapter~\ref{chap:pyfret}, in the absence of direct information about acceptor emisson behaviour, thresholding criteria are biased and do not select a random subset of fluorescent events, resulting in distortion of downstream analyses. To overcome these challenges we developed a novel analysis method, based on model-based Bayesian inference, that can simultaneously co-infer the values of all parameters of interest in a confocal smFRET dataset.

Chapter~\ref{chap:inference} presents the development and evaluation of this novel tool. Our evaluation shows that model-based inference is an effective tool for analysis of smFRET data and that we can accurately infer the concentrations and intramolecular distances of single fluorescent populations or of a mixture of two fluorescent populations. The full source code for our inference analysis is freely available online. This work provides a strong foundation for the application of model-based inference to a wider range of smFRET datasets and demonstrates the proof of concept that model-based inference is both feasible and fruitful as a method of data analysis for this research field.  

\subsection{Inference Analysis of Oligomer Sizing}
Chapter~\ref{chap:sizing} extends the concept of model-based inference and applies this form of analysis to the problem of accurately sizing heterogeneous mixtures of fluorescently labelled oligomers. A significant research effort has been made in the Klenerman group to develop experimental methodologies to allow accurate characterisation of the oligomerisation reactions observed in amyloidosis. The data analysis side of this effort has to date been somewhat neglected, allowing unfounded assumptions about the data collected to significantly reduce the accuracy of calculated oligomer size distributions.

The work presented in this chapter demonstrates, through a comparison of simulated datasets and data from simple, well-controlled experiments, that the heterogeneity observed in photon emission is not dominated, as would be hoped, by the number of fluorophores attached to a molecule. Instead, underlying photophysical processes, including, but not limited to, photobleaching, photoblinking, and the diffusion pathway of molecules through the confocal volume, have a more significant effect on the number of photons observed. Although this research was not able to provide a greatly improved analysis technique, we hope that our thorough evaluation of the challenges encountered in attempting to accuarately determine oligomer sizes, even in well-characterised, homogeneous samples, demonstrates the importance of thoroughly examining all assumptions implicit in any method of data analysis.   

\subsection{NxRepair}
The final results chapter, Chapter~\ref{chap:illumina}, presented work performed in a different research field; namely the development of NxRepair, an error correction tool for \emph{de novo} assemblies of bacterial genomes assembled from Illumina's Nextera nate pair reads. Although long-read technologies are being developed, these are either still experimental or prohibitively expensive for normal use. Consequently, the challenge of accurately reconstructing the sequence of an entire genome from short read sequences remains current. 

The work presented in this chapter demonstrates a novel method for error identification and error correction based on probabilistic analysis of the insert size distribution when mate pair reads are aligned back to the \emph{de novo} assembly. NxRepair is available online for free download and the source code is hosted on the popular code repository GitHub.  This chapter presents a comprehensive evaluation of the performcance of NxRepair using multiple bacterial genomes, demonstrating its superior performance when compared to the most popular existing error correction tool.

\section{Applications and Future Work}
%\section{Future Work}

