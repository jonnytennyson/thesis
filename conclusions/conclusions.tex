\chapter{Conclusions and Future Work}
\label{chap:conclusions}

\section{General Conclusions}
This thesis presents three years' work on understanding and improving the analysis tools used in confocal smFRET experiments. This work has involved both implementing and benchmarking existing techniques, as well as implementing and thoroughly evaluating novel methodologies. It is hoped that this work provides a strong foundation for rigorous work by other researchers in this field.

\subsection{pyFRET}
Chapter~\ref{chap:pyfret} described the development and release of an open source software library for the analysis of confocal smFRET data. For researchers working in different research environments to be able to cross-compare their results effectively, it is necessary that they have an effective method to describe and share their analysis tools and to select the best analysis tools for their specific research problem. Furthermore, smFRET data is quite sensitive to the analysis methods used.  As shown, both the specific analysis tools used and the method of their usage can quite significantly influence the appearance of the processed data and hence the outcome of downstream analyses. Unfortunately, to date there has been no culture of publishing the code or smFRET data analysis tools, which has made it difficult for researchers to compare the effectiveness and efficiency of different analysis methods.

To overcome these challenges, pyFRET, a software library that implements many of the main methodologies for analysis of smFRET data, was developed and released. pyFRET is open source and fully documented. This provides both a toolkit of analysis methods that can be freely accessed by other researchers and a platform for researchers to contribute and benchmark novel analysis methods. A rigorous comparison of different data collection and analysis methods for confocal smFRET data was also described. The evaluation presented here identifies the clear superiority of alternating excitation schemes that provide direct access to acceptor excitation information, enabling thresholding-based event selection to be carried out without bias. It is show that without direct access to information about acceptor emission, the more complex APBS and DCBS burst search algorithms display biases comparable to those seen from the simple AND and SUM thresholding algorithms, despite significantly increased space requirements and computational complexity. It is hoped that this work will facilitate research by other scientists, who can now quickly and effectively select the correct analysis tool for their data, as well as providing a platform for the publication and benchmarking of novel analysis methods.

\subsection{Inference Analysis of smFRET Data}
Thresholding-based event selection for confocal smFRET data necessarily discards a significant fraction of the smFRET dataset, including not only noise but also a large fraction of fluorescence emission events. Furthermore, as shown in Chapter~\ref{chap:pyfret}, in the absence of direct information about acceptor emission behaviour, thresholding criteria are biased and do not select a random subset of fluorescent events, resulting in distortion of downstream analyses. To overcome these challenges, a novel analysis method was developed, based on model-based Bayesian inference, that can simultaneously co-infer the values of all parameters of interest in a confocal smFRET dataset.

Chapter~\ref{chap:inference} presents the development and evaluation of this novel tool. This evaluation shows that model-based inference is an effective tool for analysis of smFRET data and that the concentrations and intramolecular distances of single fluorescent populations or of a mixture of two fluorescent populations can be accurately inferred. The full source code for our inference analysis is freely available online. This work provides a strong foundation for the application of model-based inference to a wider range of smFRET datasets and demonstrates the proof of concept that model-based inference is both feasible and fruitful as a method of data analysis for this research field.  

\subsection{Inference Analysis of Oligomer Sizing}
Chapter~\ref{chap:sizing} extends the concept of model-based inference and applies this form of analysis to the problem of accurately sizing heterogeneous mixtures of fluorescently labelled oligomers. A significant research effort has been made in the Klenerman group to develop experimental methodologies to allow accurate characterisation of the oligomerization reactions observed in amyloidosis. The data analysis side of this effort has been somewhat neglected, allowing unfounded assumptions about the data collected to significantly reduce the accuracy of calculated oligomer size distributions.

The work presented in this chapter demonstrates, through a comparison of simulated datasets and data from simple, well-controlled experiments, that the heterogeneity observed in photon emission is not dominated, as would be hoped, by the number of fluorophores attached to a molecule. Instead, underlying photophysical processes, including, but not limited to, photobleaching, photoblinking, and the diffusion pathway of molecules through the confocal volume, have a more significant effect on the number of photons observed. Although this research was not able to provide a greatly improved analysis technique, it is hoped that the thorough evaluation presented here of the challenges encountered in attempting to accurately determine oligomer sizes, even in well-characterised, homogeneous samples, demonstrates the importance of thoroughly examining all assumptions implicit in any method of data analysis.   

\subsection{NxRepair}
The final results chapter, Chapter~\ref{chap:illumina}, presented work performed in a different research field; namely the development of NxRepair, an error correction tool for \emph{de novo} assemblies of bacterial genomes assembled from Illumina's Nextera mate pair reads. Although long-read technologies are being developed, these are either still experimental or prohibitively expensive for normal use. Consequently, the challenge of accurately reconstructing the sequence of an entire genome from short read sequences remains current. 

The work presented in this chapter demonstrates a novel method for error identification and error correction based on probabilistic analysis of the insert size distribution when mate pair reads are aligned back to the \emph{de novo} assembly. NxRepair is available online for free download and the source code is hosted on the popular code repository GitHub.  This chapter presents a comprehensive evaluation of the performance of NxRepair using multiple bacterial genomes, demonstrating its superior performance when compared to the most popular existing error correction tool.

\section{Applications and Future Work}
The work presented in this thesis, and summarized above, provides a stable foundation for further work to consolidate and improve the analysis of smFRET data. Some of the results presented have encouraged experimental method development to allow more rigorous analysis of smFRET data. To conclude this thesis, some of the applications and extensions that are being considered as a result of the work described here are now summarized. 

\subsection{Open Source Software for smFRET}
pyFRET, the open source library of data analysis tools for smFRET currently provides sufficient functionality for a researcher to perform a full analysis of smFRET data collected from a range of different experiment types using a number of different methods. As the source code that implements the analysis tools, as well as the tools themselves, is freely available online it is straightforward for researchers to understand how the analysis works and to modify the tools as they require. This prevents new users of smFRET technology from needing to develop their analysis tools from scratch in order to be able to analyse their data. 

Furthermore, as experimental technologies develop and improve, it is to be expected that new analysis tools will also be required. pyFRET provides a central repository to the community to which new techniques can be added, to allow easy access and evaluations; and against which new techniques can be benchmarked; enabling researchers to make fully informed descisions about which analysis tools and experiemental methodologies to use in their research.

pyFRET already has users outside of the Klenerman research group and requests for additional features have been satisfied. There is clearly considerable work to do to allow pyFRET to become useful to a wider swathe of the smFRET research community. However, it is hoped that its existence encourages a more open, collaborative approach to smFRET data analysis and method development. 

\subsection{Inference Analysis of smFRET Data}
The work on inference analysis on smFRET data presented here clearly shows the feasibility of inference analysis as a method of analysing smFRET data. It also highlights considerable extensions and improvements to the inference method as presented here, the implementation of which would considerably increase the utility of inference as an analysis tool. The two most important of these are:

\begin{enumerate}
\item The implementation of reversible jump Monte Carlo inference~\cite{green1995}.
\item The release of the inference analysis as a software package.
\end{enumerate}

In its current implementation, the inference analysis cannot infer the number of fluorescent populations in a mixture; the number of populations must be given. This is a considerable limitation, as the number of fluorescent populations is frequently unknown. At present, determining the number of fluorescent populations can only be carried out by performing inference multiple times, modifying the number of expected fluorescent populations, and then manually inspecting the results obtained. Implementation of reversible jump Monte Carlo sampling would make this model selection step part of the inference analysis and would greatly increase the attraction of inference as a method of smFRET data analysis. 

Similarly, although the source code for the inference analysis can be viewed and downloaded from an open source code repository, the code is not packaged or documented in a manner that makes it easy to use. Packaging the analysis code as a software package, for example by incorporating it into the pyFRET framework, would make this analysis tool more accessible to other researchers. Making both of these improvements is likely to significantly improve the reception of inference analysis by smFRET researchers.

\subsection{Accurate Sizing of Fluorescent Oligomers}
Although the work on accurate oligomer sizing using inference methods was the least successful piece of research presented in this thesis in terms of successful method development, it is the work that has presented the greatest number of opportunities for further work. The results that are presented here conclusively demonstrate the role of both photophysics and the underlying experimental methodology in preventing accurate assessment of oligomer size distributions based on fluorescence data. These conclusions have led to significant re-evaluation of the experimental methods used and to the proposal of several modifications to the research methodology that may enable a more quantitative evaluation of oligomer sizes.

Specifically, the Klenerman group is currently constructing a novel confocal microscope that uses acousto-optic modulation to allow uniform excitation of the confocal volume in the $x$-dimension. By flowing labelled molecules rapidly across this region of uniform excitation using nanofluidic channels that confine the molecules to a narrow region in the $y$-dimension, it may be possible to reduce the experimental sources of emission heterogeneity. Similarly, fluorophore performance is currently being evaluated, to find commercially available structures that are more robust to photobleaching and photoblinking behaviour. A thorough evaluation of the new experimental set-up is currently in progress and it is hoped that this may lead to a more quantitative experimental methodology for determining sizes and size distributions.

\subsection{Error Detection in \emph{de novo} Assemblies}
The work presented on error correction in \emph{de novo} assemblies is predominantly self contained. An open-source error correction tool was developed and released. This tool is currently used by bioinformaticians at Illumina; an evaluation of the tool's performance forms the basis for a peer reviewed publication~\ref{murphy2015}. Extensions of this tool include modifications to enable larger genome assemblies to be evaluated and to allow evaluation of \emph{de novo} assemblies prepared using alternative sequencing methodologies, such as the long-reads from Nanopore sequencing that can be ``threaded'' through a de Bruijn graph to resolve ambiguities~\cite{Koren2015}. Modification of the tool to enable chaining with other assembly and quality control tools is also possible. Implementation of these additions depends on demand and uptake from other bioinformaticians. It is hoped that NxRepair finds an interested user-base within the bioinformatics research community.
